{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPF+U2hv6HpxW5GCAYMdqfT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taizun-jj202/PyTorch_Basics/blob/NN/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8WG1bSne76J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import  torch.nn as nn\n",
        "from torch.utils.data import DataLoader     # Loads data into training and test batches\n",
        "import torchvision.datasets as datasets     # Gives the proper dataset from Pytorch\n",
        "import torchvision.transforms as transfroms\n",
        "import torch.nn.functional as F             # Contains activation functions\n",
        "import  torch.optim as optim                # Contains optimizers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Hyperparameters\n",
        "in_channel = 1\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "learning_rate = 0.001\n"
      ],
      "metadata": {
        "id": "40gj-IFOfCSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resource : https://learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/#:~:text=Size%20of%20Output%20Tensor%20(Image)%20of%20a%20MaxPool%20Layer&text=%3D%20Pool%20size.&text=same%20as%20the%20kernel%20size,maxpool%20layer's%20output%20is%20unchanged.&text=So%2C%20the%20output%20image%20is%20of%20size%2027x27x96.\n",
        "# Resource2: https://androidkt.com/calculate-output-size-convolutional-pooling-layers-cnn/\n"
      ],
      "metadata": {
        "id": "doA46AQOfEdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the NN\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes = 10, in_channels = 1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d( in_channels=1, out_channels=16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "        self.pool = nn.MaxPool2d( kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.conv2 = nn.Conv2d( in_channels=16, out_channels=32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "        self.pool = nn.MaxPool2d( kernel_size=(1, 1), stride=(1, 1)) # Size of output 28*28*32\n",
        "        self.fc1 = nn.Linear( in_features=28*28*32, out_features=100)\n",
        "        self.fc2 = nn.Linear( in_features=100, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "pVutJ19QfGXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading and splitting the data\n",
        "train_ds = datasets.FashionMNIST( root= 'datasetFMNIST/',\n",
        "                                  train= True,\n",
        "                                  download=True,\n",
        "                                  transform= transfroms.ToTensor())\n",
        "train_load = DataLoader( dataset = train_ds,\n",
        "                         batch_size= batch_size,\n",
        "                         shuffle= True)\n",
        "\n",
        "test_ds = datasets.FashionMNIST( root='datasetFMNIST/',\n",
        "                                 transform=transfroms.ToTensor(),\n",
        "                                 download=True,\n",
        "                                 train=False)\n",
        "test_load = DataLoader( dataset = test_ds,\n",
        "                        batch_size= batch_size,\n",
        "                        shuffle= True)\n"
      ],
      "metadata": {
        "id": "PjA81kUnfOS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Validating the model:\n",
        "def validate(loader, model):\n",
        "\n",
        "    correct = 0\n",
        "    tot_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (data, index) in loader:\n",
        "            data = data.to(device)\n",
        "            index = index.to(device)\n",
        "\n",
        "            score = model(data)\n",
        "            _, result = torch.max(data, 1)\n",
        "\n",
        "            correct += (result == index).sum()\n",
        "            tot_samples += result.size(0)       # Checks how many rows have passed i.e the no. of samples as 1row = 1 sample\n",
        "\n",
        "        print(f\"Accuracy : {float(correct) / float(tot_samples)}, Samples: {correct} / {tot_samples}\")\n",
        "    #model.train()"
      ],
      "metadata": {
        "id": "_D4bMXEOfQ3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(loader, model):\n",
        "    if loader.dataset.train :\n",
        "        print(\"Checking accuracy on training data\")\n",
        "    else:\n",
        "        print(\"Checking accuracy on testing data\")\n",
        "\n",
        "    num_correct = 0\n",
        "    num_passes = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (x, y) in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _ ,  pred = scores.max(1)\n",
        "            num_correct += (pred == y).sum()\n",
        "            num_passes += pred.size(0)\n",
        "        print(f\"Got {num_correct}/{num_passes} with accuracy {float(num_correct)/float(num_passes)*100}\")\n",
        "\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "F9B1fRTjgOcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training the model :\n",
        "def train(loader,  model):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(),  lr = learning_rate)\n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (data,index) in enumerate(loader):\n",
        "            data = data.to(device)\n",
        "            index = index.to(device)\n",
        "\n",
        "            # Calculating loss function based on 'data' input\n",
        "            loss = criterion(model(data), index)\n",
        "\n",
        "            # Using optimizer to calculate lowest gradient\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n"
      ],
      "metadata": {
        "id": "RNptE46lfVm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the NN\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "FM_NN = CNN().to(device)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CNvGq_IvfYEt",
        "outputId": "e766deba-b1ac-4dbc-8bde-21346a4a1f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output of the model\n",
        "print(\"Training the model :\")\n",
        "train(train_load, FM_NN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5AxWjN4faqM",
        "outputId": "82ca040d-369c-462d-9f05-787130de6372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model :\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Accuracy on train data :\")\n",
        "validate(train_load, FM_NN)\n",
        "validate(test_load, FM_NN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "lxYX2xtFgiCr",
        "outputId": "8e1f9a61-fd0e-4fdd-d41b-f51aafd01956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train data :\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-adf6d1f239e5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy on train data :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFM_NN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFM_NN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-86c72ee1665a>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(loader, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtot_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# Checks how many rows have passed i.e the no. of samples as 1row = 1 sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (28) must match the size of tensor b (64) at non-singleton dimension 2"
          ]
        }
      ]
    }
  ]
}